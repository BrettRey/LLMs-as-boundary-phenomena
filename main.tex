\documentclass[12pt]{article}

% House style preamble
\input{.house-style/preamble.tex}

% Update PDF metadata
\hypersetup{
  pdftitle={LLMs as boundary phenomena}
}

\title{LLMs as boundary phenomena}
\author{Brett Reynolds \orcidlink{0000-0003-0073-7195}%
\thanks{Contact: \href{mailto:brett.reynolds@humber.ca}{brett.reynolds@humber.ca}}\\
Humber Polytechnic \& University of Toronto}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
The debate over whether large language models \enquote{really think} reproduces a familiar pattern: a boundary case meets a binary classification. \textcite{nefdt2026} organizes this debate through a $2\times 2$ matrix crossing language with cognition, placing LLMs in a \enquote{missing quadrant} of language without cognition. But the binary frame undersells his own insights. His hedging on proxies, partial capacities, and qualified attributions points toward something the table can't express: that language and cognition are cluster concepts with graded boundaries. \term{Homeostatic property cluster} (HPC) theory and projection-purpose analysis offer a better framework. The same LLM capacities get categorized as \enquote{linguistic} or \enquote{cognitive} depending on the analytical purpose, the same phenomenon that makes a tomato a vegetable or a fruit depending on whether you're a greengrocer or a botanist.
\end{abstract}

\section{Introduction}

Everyone has an opinion about whether ChatGPT \enquote{really thinks.} The debate reproduces a pattern familiar from philosophy of science: a boundary case meets a binary classification, and the deadlock gets mistaken for a factual disagreement.

\textcite{nefdt2026} offers a sophisticated analysis. He frames the conceptual landscape through a $2\times 2$ matrix (his Table~1) crossing language with cognition. Humans have both. Non-human animals have cognition without language. LLMs, Nefdt argues, fill the \enquote{missing quadrant}: language without cognition (p.~4). They're \enquote{purely linguistic agents unplugged from integration with both larger cognitive structure and the world in which it evolved} (p.~12).

The table carves out genuine conceptual space and steers between the eliminativism of \textcite{bender2020} and the maximalism of \textcite{cappelen2025}. But its binary structure undersells Nefdt's own insights. His discussion is full of hedging, proxies, and qualified answers~-- scalar claims that a binary frame can't capture.

This note argues that \term{homeostatic property cluster} (HPC) theory \citep{boyd1991, boyd1999} handles the LLM case better. HPC theory deals with kinds defined not by necessary and sufficient conditions but by clusters of co-occurring properties held together by causal mechanisms. Which properties matter depends on what the categorization is for. This explains why the debate is so persistent. Nefdt's hedging is a feature, not a bug.

\section{The binary and its discontents}

Nefdt's Table~1 is a $2\times 2$ matrix crossing language with cognition:

\begin{table}[ht]
\centering
\begin{tabular}{lcc}
\toprule
 & +Cognition & --Cognition \\
\midrule
+Language & Humans & ??? \\
--Language & Non-human animals & Rocks \\
\bottomrule
\end{tabular}
\caption{Conceptual possibilities, adapted from \textcite{nefdt2026}, p.~4.}
\label{tab:nefdt}
\end{table}

The open question is whether anything occupies the top-right cell: language without cognition. Nefdt's answer is that LLMs fill it. They \enquote{occupy a hitherto vacant part of conceptual space} (p.~4). The table presupposes that \term{language} and \term{cognition} are necessary-and-sufficient-condition categories. Something either has language or it doesn't, either has cognition or it doesn't, and the philosophical work consists in deciding which cell a system occupies. One might object that the table is scaffolding, not a metaphysical commitment~-- a heuristic to organize the debate, not a claim that the categories are really binary. But even heuristic binaries constrain the conceptual space they organize: a table with two columns invites two-valued answers. The hedging that runs through Nefdt's discussion is his own analysis pressing against that constraint.

Consider the evidence. His \textsc{no brainer} principle states that \enquote{LLMs only model one aspect of cognition, namely (statistical) linguistic processing} (p.~6). This already blurs the boundary between columns: if statistical linguistic processing is an \enquote{aspect of cognition,} then LLMs don't simply lack cognition. They instantiate part of it.

\textsc{Cognition unplugged} goes further, drawing on \posscite{casto2025} distinction between \enquote{linguistic understanding} and \enquote{deep understanding.} Nefdt concludes that purely linguistic agents have \enquote{statistically-based proxies for more cognitively loaded states} (p.~8). But proxies aren't absences. This isn't just epistemic hedging (we're uncertain which cell LLMs belong in). It's evidence of ontological continuity: a proxy for reasoning is on the same continuum as reasoning, better explained by cluster structure than by binary uncertainty.

The hedging continues throughout section~4. On perspective: LLMs can be \enquote{trained to execute a particular point of view} (p.~10), but \enquote{the individual phenomenal level is missing} (p.~10). On time: they don't clearly have or lack temporal cognition; rather, \enquote{they could depending on the kinds of structures they employ} (p.~12). On cognitive agency generally: Nefdt titles his section~4.3 \enquote{Why I'm neither a realist nor an eliminativist} and locates himself in \enquote{a nonempty position in between} the two poles (p.~12).

These aren't binary verdicts. They're positions along a continuum. The properties Nefdt distributes between \enquote{language} and \enquote{cognition} (inferential reasoning, perspective-taking, temporal processing, phenomenal experience) don't sort cleanly into two groups. They cluster, with graded and contested membership at the boundaries. As \textcite{mahowald2024} show, language and thought \enquote{dissociate} in LLMs, but partially and unevenly~-- not along a clean binary divide.

\section{HPC reframing}

HPC theory was developed by \textcite{boyd1991, boyd1999} to handle \term{natural kinds} that resist definition by necessary and sufficient conditions. The framework is contested (see, e.g., \citealt{magnus2014} for objections), but the core insight~-- that kind membership can be graded and mechanism-dependent~-- is widely shared even among critics. Biological species are the paradigm case. There's no single property that all and only tigers share. Instead, there's a cluster of properties (striped fur, carnivorous diet, specific chromosome count, territorial behaviour) that tend to co-occur because of underlying causal mechanisms: shared genome, developmental constraints, ecological pressures. The cluster holds even when individual properties vary.

The framework applies to language and cognition. In humans, properties like inferential reasoning, pragmatic implicature, analogical mapping, perspective-taking, planning, emotional response, and embodied experience cluster together. They do so because of homeostatic mechanisms: shared neural architecture, developmental trajectories, social interaction patterns, and embodied engagement with the world.

But the clustering is contingent, not definitional. The properties co-occur in humans because of the particular causal structure of human biology and development, and LLMs instantiate a novel combination from this cluster. They display some properties typically associated with cognition (inferential reasoning, analogical mapping, something like perspective-taking) while lacking others (embodied experience, persistent memory, emotional states, autonomous goal-formation). This doesn't make them a clean occupant of a \enquote{missing quadrant.} It makes them a boundary case in cluster space: exactly the kind of entity HPC theory was designed to handle and that binary categories systematically misclassify.

\posscite{powell2020} convergence/contingency framework helps clarify which properties to expect in a novel system. Some properties are \term{convergent}: they recur across unrelated systems because similar functional pressures produce similar solutions. Pattern extraction and inferential reasoning may be convergent: any system under sufficient pressure to predict and generate natural language is likely to develop something functionally similar. Other properties are \term{contingent}: they depend on specific implementation history. The absence of embodiment in LLMs is a contingent feature of their engineering, not a deficit. The absence of phenomenal consciousness may be contingent too, or it may reflect deeper architectural constraints~-- an empirical question, not a definitional one. Either way, the framework predicts exactly what we observe: a system that shares some cluster properties and lacks others, with the specific combination shaped by causal mechanisms rather than by a definitional boundary. A further dimension this note doesn't develop is etiological: it matters not just which properties cluster but how they came to do so. Boyd's HPC framework was designed for natural kinds whose clustering arises from natural causal processes; in LLMs, the clustering is engineered. Whether this difference undermines the analogy is a question for another paper.

\section{The tomato move}

There's a further problem with the binary. Even granting that LLMs occupy some definite cell, we'd need to ask: definite relative to what?

The same LLM capacities get categorized as \enquote{linguistic} or \enquote{cognitive} depending on the \term{projection purpose} \citep[cf.][]{Goodman1955}: the interest or analytical goal that determines which similarities count and therefore what falls inside the category. Consider three projections.

Under a neuroscience projection, we ask what mechanism produces the behaviour. LLMs process tokenized text via vector operations and statistical pattern-matching. By this criterion, their capacities are linguistic: produced by something analogous to a language-processing system, not by the full suite of cognitive machinery.

Under a functional projection, we ask what the system does. LLMs draw inferences, construct analogies, adopt perspectives, and plan multi-step solutions. By this criterion, their capacities are cognitive: they exhibit the functional profile of cognition regardless of the underlying mechanism.

Under a phenomenological projection, we ask whether there is something it is like to be the system \citep{nagel1974}. The answer for LLMs is probably no, or at least undecidable from the outside. By this criterion, the question of cognition can't be resolved.

This is the tomato problem. To a greengrocer, a tomato is a vegetable: it's savoury, shelved with the peppers and onions. To a botanist, it's a fruit: it develops from the ovary of a flower and contains seeds. Neither classification is wrong. Each serves a different purpose, and the disagreement dissolves once you specify which purpose you're serving. But perspectival doesn't mean inconsequential. The US Supreme Court ruled in \emph{Nix v.\ Hedden} (1893) that tomatoes are vegetables for tariff purposes~-- a projection-purpose dispute with real economic stakes. Whether LLMs \enquote{really think} has analogous consequences for regulation, liability, and intellectual-property law.

Nefdt's Table~1 implicitly places more weight on what produces the behaviour than on what the behaviour achieves. LLMs lack the neural substrates and embodied integration associated with cognition in humans, so they go in the \enquote{language without cognition} cell. But this is a consequence of the projection chosen, not a discovery about LLMs. Under the functional projection, the same systems would land in \enquote{language and cognition}~-- and \textcite{cappelen2025} effectively argue for exactly this placement.

The persistence of the \enquote{do LLMs really think?} debate is predicted by the HPC framework. It's a projection-purpose dispute disguised as an ontological one. Resolving it doesn't require discovering a hidden fact about LLMs. It requires specifying the purpose of the categorization.

\section{Why this matters}

The LLM case isn't just applied philosophy of AI. It's a publicly accessible illustration of how projection purposes shape categorization. Everyone already has intuitions about whether ChatGPT \enquote{really thinks,} which makes LLMs an unusually vivid test case for the general point.

Nefdt's analysis is better served by the HPC framework than by his table. His hedging, his \enquote{neither realist nor eliminativist} stance, his acknowledgment of proxies and partial capacities~-- these are exactly what HPC theory predicts for boundary cases. The framework doesn't force him to choose a cell. It lets him say what he already wants to say: that LLMs share some cluster properties with cognitive agents, lack others, and that the combination is genuinely novel. The binary table does have one virtue: it forces a commitment. HPC's flexibility is also its risk, since a framework that accommodates everything explains nothing. The claim here is narrower: for \emph{this} boundary case, the cluster structure is more informative than the binary.

The framework also explains why eliminativists and maximalists talk past each other. \textcite{bender2020} adopt something like a neuroscience projection: LLMs don't ground meaning in embodied experience, so they don't understand language. \textcite{cappelen2025} adopt a functional projection: LLMs exhibit the behavioural profile of cognitive agents, so they do understand. Each is right relative to its projection purpose. The disagreement is irresolvable as long as both sides treat it as ontological rather than perspectival.

The question isn't whether LLMs \enquote{really} have cognition. It's which properties cluster, under what mechanisms, for what analytical purpose. That's the HPC question, and it has more interesting answers than yes or no.

\section*{Acknowledgements}

This note was drafted with the assistance of Claude Code (Opus 4.6). I have reviewed and revised all content and take full responsibility for the final text.

\newpage
\printbibliography

\end{document}
